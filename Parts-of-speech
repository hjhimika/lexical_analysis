#Parts-of-speech
import nltk
from nltk.tokenize import word_tokenize
from nltk import pos_tag

# Download the required resources
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

text = "GeeksforGeeks is a Computer Science platform."

# Tokenize the text
tokenized_text = word_tokenize(text)

# Get parts of speech tags
tags = pos_tag(tokenized_text)

print(tags)
